{
 "cells": [
  {
   "source": [
    "# Deep learning for cell biology 101\n",
    "This is first part of a tutorial series about deep learning.\n",
    "Well 90% of this tutorial will be general for everyone that wants to learn about deep learning, the focus will lay on cell biology, and the sometimes uniques problems and solutions needed there.\n",
    "\n",
    "This first part is about setting up the most simple full flow.\n",
    "- Loading and preparing data\n",
    "- Getting a model\n",
    "- Training a model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\tomni\\anaconda3\\envs\\tf_gpu_2_3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\nC:\\Users\\tomni\\anaconda3\\envs\\tf_gpu_2_3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\nC:\\Users\\tomni\\anaconda3\\envs\\tf_gpu_2_3\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tomni import bbox_fitting_center\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# This is some code for when you only have 1 GPU in your computer.\n",
    "# If you have multiple or none it will still work fine\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "N_EPOCHES = 20\n",
    "IMAGE_DIM = 128"
   ]
  },
  {
   "source": [
    "## Loading the data\n",
    "\n",
    "In this notebook we will be using a maleria dataset: https://lhncbc.nlm.nih.gov/publication/pub9932.\n",
    "This dataset contains 13779 of images of healthy red blood cells. \n",
    "And 13779 of images of maleria infected red blood cells. \n",
    "\n",
    "We will do very little clever things in this notebook and try to stay to the basics as much as possible.\n",
    "This means the results, training speed and prediction speed all can be better.\n",
    "We will look into better technices later in the series.\n",
    "\n",
    "We will load all the data directly into our memory from our own hard disk.\n",
    "This is the easiest way to start but not the most efficient.\n",
    "In later sessions we will explore a better method.\n",
    "\n",
    "All images need to have the same size for training.\n",
    "So we add cropping and/or padding to every image to make them 128x128 without scaling them.\n",
    "Scaling is something you try to avoid in cell biology because everything will have the same pixels per mm.\n",
    "So training on scaled images does not make sense.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all the paths\n",
    "\n",
    "data_location_uninfected=r\"D:\\data\\malaria_dataset\\Uninfected\"\n",
    "data_location_parasitized=r\"D:\\data\\malaria_dataset\\Parasitized\"\n",
    "\n",
    "all_uninfected_paths = [os.path.join(data_location_uninfected, i) for i in os.listdir(data_location_uninfected) if i.endswith(\".png\")]\n",
    "all_parasitized_paths = [os.path.join(data_location_parasitized, i) for i in os.listdir(data_location_parasitized) if i.endswith(\".png\")]\n",
    "\n",
    "shuffle(all_parasitized_paths)\n",
    "shuffle(all_uninfected_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = bbox_fitting_center(img, (IMAGE_DIM, IMAGE_DIM))\n",
    "    return img\n",
    "\n",
    "all_uninfected_images = [load_and_preprocess(path) for path in all_uninfected_paths]\n",
    "all_parasitized_images = [load_and_preprocess(path) for path in all_parasitized_paths]"
   ]
  },
  {
   "source": [
    "## Let's have a look at the data we are dealing with\n",
    "\n",
    "We will vizualize 64 random images and its labels just to see what we are dealing with.\n",
    "This is done to give an idea of how things look like, and can help us make descision later on."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "for i, image in enumerate(all_parasitized_images[:32]):\n",
    "  ax = plt.subplot(8, 8, i + 1)\n",
    "  plt.imshow(image)\n",
    "  plt.title(\"Parasitized\")\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "for i, image in enumerate(all_uninfected_images[:32]):\n",
    "  ax = plt.subplot(8, 8, i + 33)\n",
    "  plt.imshow(image)\n",
    "  plt.title(\"Unifected\")\n",
    "  plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Getting the model\n",
    "We will download the [EfficientNet B0](https://arxiv.org/abs/1905.11946). \n",
    "This is a network is very optimized for speed and accuracy.\n",
    "B0 means maximum speed, B7 is maximum accuracy.\n",
    "\n",
    "We can download the model but the model is made the predict a thousand classes.\n",
    "So we download the model without the top."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "\n",
    "effienct_net_b0 = EfficientNetB0(include_top=False, weights=None, input_shape=(IMAGE_DIM, IMAGE_DIM, 3))\n"
   ]
  },
  {
   "source": [
    "Lets make a prediction with the model.\n",
    "If we do so we can see our input image (with the shape `[1, 128, 128, 3]`) it turned into a array of shape `[1, 4, 4, 1280]`.\n",
    "\n",
    "In here the first 1 is the number of images.\n",
    "\n",
    "The second 2 numbers are the dimensions, 128x128 is the size of the image, 4x4 is the width and height of the output.\n",
    "\n",
    "The last number is number of features.\n",
    "Each pixel has 3 values when it gets in (red, green and blue) and 1280 features when it gets out.\n",
    "What those features are we don't know, the model will determin these when training."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.array([all_uninfected_images[0]])\n",
    "\n",
    "p = effienct_net_b0.predict(test_image)\n",
    "\n",
    "print(p.shape)"
   ]
  },
  {
   "source": [
    "We need the change the output size to something that makes sense.\n",
    "Each picture is either infected or not.\n",
    "So we can use 1 number to describe them, a 0 if healthy and a 1 if infected.\n",
    "\n",
    "So the output size should be `[1, 1]`.\n",
    "\n",
    "To do this we will first add a maxpool2d.\n",
    "What a maxpool2d is a sliding window maximum filter that also reduces the size of the image.\n",
    "\n",
    "If we add it with a size of 4x4 our output will be reduced to a `[1, 1, 1, 1280]`.\n",
    "\n",
    "[image1]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "max_pool = MaxPooling2D((4, 4))(effienct_net_b0.output)\n",
    "\n",
    "input_layer = effienct_net_b0.input\n",
    "model = Model(input_layer, max_pool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(test_image)\n",
    "\n",
    "print(p.shape)"
   ]
  },
  {
   "source": [
    "Next up we want to reduce the number of features from 1280 to 1.\n",
    "For this we use another layer, but this time a 2D convolution layer.\n",
    "\n",
    "Convolution layer are also sliding windows, just like max pool, but they do matrix multiplication instate of maximum filter.\n",
    "This matrix is called a kernel.\n",
    "Convolution layers do not reduce the size of the image.\n",
    "Because our image is already 1x1 we only can fit a kernel of 1x1.\n",
    "\n",
    "But the kernel has a third dimension, the number of features.\n",
    "We do not have the give this number Tensorflow we figure it out himself.\n",
    "It will be 1280 because of the input size of this layer.\n",
    "\n",
    "We can pick how many of these kernels we want.\n",
    "Because we want to have an output size of 1 we pick 1.\n",
    "\n",
    "[image2]\n",
    "\n",
    "We also give this layer an activation.\n",
    "An activation is a function that get applied after this layer.\n",
    "We use sigmoid.\n",
    "This is done to make sure all values are inbetween 0 and 1.\n",
    "If we did not use sigmoid all the values would be inbetween $-\\infty$ and $\\infty$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "conv2d = Conv2D(1, (1, 1), activation=\"sigmoid\")(max_pool)\n",
    "\n",
    "model = Model(input_layer, conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(test_image)\n",
    "\n",
    "print(p.shape)"
   ]
  },
  {
   "source": [
    "lastly we want get rid of the dimenisions for width and height.\n",
    "This is what flatten does for us.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = Flatten()(conv2d)\n",
    "\n",
    "model = Model(input_layer, flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(test_image)\n",
    "\n",
    "print(p.shape)"
   ]
  },
  {
   "source": [
    "Great, we have our model.\n",
    "We can have a look at our full model (efficent net b0 with our own top) by using \n",
    "```python \n",
    "model.summary()\n",
    "```\n",
    "\n",
    "I will skip it because it has a long output without a lot of intresting things (for now)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Preparing data for training\n",
    "The data need a little bit of preparation.\n",
    "- First of all it needs to become 1 list with all data not 2 lists.\n",
    "- Secondly there needs to be something to predict.\n",
    "\n",
    "We are training a superviced model, this means we have the input (the image of a bloodcell) and a known label (is it infected or not).\n",
    "A model can not predict a class only a number so we replace infected with 1 and not infected with a 0.\n",
    "\n",
    "This makes sure our expected labels (y) is the same shape as the predictions of the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_uninfected_images + all_parasitized_images\n",
    "y = [0] * len(all_uninfected_images) + [1] * len(all_parasitized_images)\n",
    "\n",
    "# we make the numpy arrays because tensorflows doesn't like lists\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "source": [
    "## Loss & optimalization\n",
    "\n",
    "Now we have our model and data we need 2 more things before we can train our model.\n",
    "\n",
    "We need a way to determin how well the model does at every given moment.\n",
    "For this we use the labels and the prediction to calculate 1 number.\n",
    "The function what does this for us is the loss function.\n",
    "\n",
    "Secondly we need a way to optimize a model so that every step the loss gets smaller.\n",
    "This will be our optimizer.\n",
    "\n",
    "For the loss we will use mean_absolute_error.\n",
    "This will calculate the average difference between the labels and predictions.\n",
    "\n",
    "For the optimizer we will use stogastic gradient descent.\n",
    "For now it is not very imported to understand them, and there are people who do this way better then I ever can.\n",
    "\n",
    "Both of these are standard options in tensorflow.\n",
    "\n",
    "We will also add a metric for accuracy, just because it is intresting."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"sgd\", loss=\"mean_absolute_error\", metrics=['accuracy'])"
   ]
  },
  {
   "source": [
    "## Training the model\n",
    "\n",
    "We have our data, we have our model, we have complied our model with a loss function and optimizer.\n",
    "So now we can start right?\n",
    "\n",
    "Yes, we, can!\n",
    "\n",
    "To train the model we use the fit function.\n",
    "We give it the data.\n",
    "And the number of times we want to go throught all the data (epochs).\n",
    "\n",
    "It will output some history we can plot.\n",
    "\n",
    "*technical part:*\n",
    "\n",
    "If this goes really slow check if your GPU is used.\n",
    "If not, try to fix it or be patient.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x, y, epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy without pre-training')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim([0.5,1])\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss without pre-training')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "Looking at the plots belowe we can see that the accuracy goes up and the loss goes down.\n",
    "\n",
    "That is exactly what we want.\n",
    "\n",
    "Lets now try this model on a few of a pictures.\n",
    "\n",
    "footnote:\n",
    "\n",
    "We use now the same pictures for testing and training, this is not a good idea for the same reason you should not give an exam question to a student before the exam.\n",
    "\n",
    "We will fix that later."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parasitized_predictions = model.predict(np.array(all_parasitized_images[:32]))\n",
    "uninfected_predictions = model.predict(np.array(all_uninfected_images[:32]))\n",
    "\n",
    "print(\"parasitized_predictions\",\n",
    "parasitized_predictions)\n",
    "\n",
    "print(\"uninfected_predictions\",\n",
    "uninfected_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('tf_gpu_2_3': conda)",
   "metadata": {
    "interpreter": {
     "hash": "41c5f08fd158a0754024ea8f3c82ac5d41478658fcf1bc7559b6a059d2421cf8"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}